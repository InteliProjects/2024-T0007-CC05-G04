{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import carregamento # custom python file that loads the data from the json file and exports as csv's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processamento dos dados\n",
    "\n",
    "Leva cerca de 5 minutos... Gera arquivos \".csv\" no diretório de caminho \"./csvs/\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initialized data processing.\")\n",
    "carregamento.start()\n",
    "print(\"Finished processing the data. Beginning the treatment process.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variáveis globais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specialFiles = [empty csv, content of that empty csv]\n",
    "specialFiles = [\"associacaoProdutoGrupo.csv\", \"id_associacaoProdutoGrupo.csv\"]\n",
    "csvFilesPath = \"./csvs/\"\n",
    "csvFiles = [f for f in os.listdir(csvFilesPath) if f not in specialFiles]\n",
    "alteredFiles = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções de exportar, carregar e deletar arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export(df : pd.DataFrame, fileName):\n",
    "    df.to_csv(csvFilesPath + fileName, index=False)\n",
    "\n",
    "\n",
    "def load(fileName : str):\n",
    "    return pd.read_csv(csvFilesPath + fileName)\n",
    "\n",
    "\n",
    "def deleteFile(fileName : str):\n",
    "    if os.path.exists(csvFilesPath + fileName):\n",
    "        os.remove(csvFilesPath + fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline para agregar subtabelas nas tabelas principais\n",
    "\n",
    "(quando possível)\n",
    "\n",
    "No carregamento dos dados, subtabelas recebem um identificador no formato \"tabelaPrincipalId\", que na verdade diz respeito ao índice (linha) a que os dados da subtabela pertencem na tabela principal. Como o índice das linhas começa em 0, a função \"idToIndex\" garante que o menor valor do identificador na subtabela será 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idToIndex(df : pd.DataFrame, idCol : str):\n",
    "    df[idCol] -= df[idCol].min()\n",
    "    df = df.sort_values(idCol).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def tryAddToMainTable(df : pd.DataFrame, mainFileName : str, otherFileName : str):\n",
    "    if not os.path.exists(csvFilesPath + mainFileName + \".csv\"):\n",
    "        return\n",
    "    \n",
    "    main = load(mainFileName + \".csv\").reset_index()\n",
    "    \n",
    "    idCol = mainFileName + \"Id\"\n",
    "    main.rename(columns={'index': idCol}, inplace=True)\n",
    "    main = main.merge(df, \"left\", on=idCol)\n",
    "    main = main.sort_values(idCol).drop(idCol, axis=1)\n",
    "    \n",
    "    export(main, mainFileName + \".csv\")\n",
    "    deleteFile(otherFileName)\n",
    "    print(otherFileName + \" added to main table \" + mainFileName + ' and deleted from \"csvs\" directory.')\n",
    "    print(\"----------------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "def trySubtablePipeline(fileName : str):\n",
    "    global alteredFiles\n",
    "\n",
    "    df = load(fileName)\n",
    "    idCol = [c for c in df.columns if c.endswith(\"Id\")]\n",
    "    \n",
    "    if not len(idCol):\n",
    "        return\n",
    "    \n",
    "    idToIndex(df, idCol[0])\n",
    "    tryAddToMainTable(df, idCol[0].removesuffix(\"Id\"), fileName)\n",
    "    alteredFiles += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento de caso especial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the content of the csv file, putting it in the empty file and deleting the first\n",
    "specialCase = load(specialFiles[1])\n",
    "idToIndex(specialCase, \"associacaoProdutoGrupoId\")\n",
    "specialCase.drop(\"associacaoProdutoGrupoId\", axis=1, inplace=True)\n",
    "export(specialCase, specialFiles[0])\n",
    "deleteFile(specialFiles[1])\n",
    "alteredFiles += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execução da Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fileName in csvFiles:\n",
    "    trySubtablePipeline(fileName)\n",
    "\n",
    "print(\"Number of alterations made: \" + str(alteredFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Current number of csv files in \"csvs\" directory: ' + str(len(os.listdir(csvFilesPath))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento específico\n",
    "\n",
    "Após simples análise manual, localizou-se alguns casos específicos que poderiam ser tratados de forma individualizada para simplificar os dados. Logo, esse tratamento foi realizado abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### idElo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idElo():\n",
    "    print(\"Working on idElo\")\n",
    "    idToValues = {2228: \"[1551, 1937, 2308]\", 2229: \"[1551, 1937, 2308]\", 1699: \"[1551, 1937, 2308]\",\n",
    "                  1700: \"[1551, 1937, 2308]\", 1702: \"[1740, 1742]\", 1703: \"[1741, 1743]\", 1704: \"[1211, 1214, 1692, 1740, 1742, 1829]\"}\n",
    "\n",
    "    main = load(\"pontoCargaDescargaAPS.csv\").set_index(\"id\")\n",
    "    main[\"idElo\"] = None\n",
    "\n",
    "    for i in idToValues.keys():\n",
    "        main.at[i, \"idElo\"] = idToValues[i]\n",
    "    \n",
    "    export(main.reset_index(), \"pontoCargaDescargaAPS.csv\")\n",
    "    print('Modified \"pontoCargaDescargaAPS.csv\".')\n",
    "\n",
    "    deleteFile(\"idElo.csv\")\n",
    "    print('Deleted \"idElo.csv\". Use \"pontoCargaDescargaAPS.csv\" instead.')\n",
    "    print(\"----------------------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pesoMedioTransporteProduto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pesoMedioTransporteProduto():\n",
    "    print(\"Working on pesoMedioTransporteProduto\")\n",
    "    subtable = load(\"pesoMedioTransporteProduto_pesosMediosTransporteProduto.csv\").drop(\"pesosMediosTransporteProdutoId\", axis=1)\n",
    "    main = load(\"pesoMedioTransporteProduto.csv\")\n",
    "\n",
    "    print(\"Subtable length (rows): \" + str(len(subtable)))\n",
    "    print(\"Main table length (rows): \" + str(len(main)))\n",
    "\n",
    "    final = pd.concat([subtable, main])\n",
    "    print(\"Merged table length (rows): \" + str(len(final)))\n",
    "    \n",
    "    export(final, \"pesoMedioTransporteProduto.csv\")\n",
    "    print('Modified \"pesoMedioTransporteProduto.csv\".')\n",
    "\n",
    "    deleteFile(\"pesoMedioTransporteProduto_pesosMediosTransporteProduto.csv\")\n",
    "    print('Deleted \"pesoMedioTransporteProduto_pesosMediosTransporteProduto.csv\". Use \"pesoMedioTransporteProduto.csv\" instead.')\n",
    "    print(\"----------------------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regraBlendagemProduto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regraBlendagemProduto():\n",
    "    print(\"Working on regraBlendagemProduto\")\n",
    "    subtable = load(\"regraBlendagemProduto_regrasBlendagemProduto.csv\").drop(\"regrasBlendagemProdutoId\", axis=1)\n",
    "    main = load(\"regraBlendagemProduto.csv\")\n",
    "\n",
    "    print(\"Subtable length (rows): \" + str(len(subtable)))\n",
    "    print(\"Main table length (rows): \" + str(len(main)))\n",
    "    \n",
    "    final = pd.concat([subtable, main])\n",
    "    \n",
    "    print(\"Merged table length (rows): \" + str(len(final)))\n",
    "    \n",
    "    export(final, \"regraBlendagemProduto.csv\")\n",
    "    print('Modified \"regraBlendagemProduto.csv\".')\n",
    "\n",
    "    deleteFile(\"regraBlendagemProduto_regrasBlendagemProduto.csv\")\n",
    "    print('Deleted \"regraBlendagemProduto_regrasBlendagemProduto.csv\". Use \"regraBlendagemProduto.csv\" instead.')\n",
    "    print(\"----------------------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### siteProdutivoAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def siteProdutivoAPS():\n",
    "    print(\"Working on siteProdutivoAPS\")\n",
    "    if os.path.exists(csvFilesPath + \"siteProdutivoAPS.csv\"):\n",
    "        os.remove(csvFilesPath + \"siteProdutivoAPS.csv\")\n",
    "        print('Deleted \"siteProdutivoAPS.csv\".')\n",
    "    print(\"----------------------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submodalTransporte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submodalTransporte():\n",
    "    print(\"Working on submodalTransporte\")\n",
    "    idToValues = {1707 : \"['GDE', 'MIS']\", 1995: \"['DIV', 'GDE']\"}\n",
    "\n",
    "    submodalTable = load(\"submodalTransporte.csv\")\n",
    "    submodalTable.drop([c for c in submodalTable.columns if c.startswith(\"0\")], axis=1, inplace=True)\n",
    "    \n",
    "    export(submodalTable.iloc[0:len(submodalTable) - 5], \"submodalTransporte.csv\")\n",
    "    print('Modified \"submodalTransporte.csv\".')\n",
    "\n",
    "    pontoCargaTable = load(\"pontoCargaDescargaAPS.csv\").set_index(\"id\")\n",
    "\n",
    "    for i in idToValues.keys():\n",
    "        pontoCargaTable.at[i, \"submodalTransporte\"] = idToValues[i]\n",
    "    \n",
    "    export(pontoCargaTable.reset_index(), \"pontoCargaDescargaAPS.csv\")\n",
    "    print('Modified \"pontoCargaDescargaAPS.csv\".')\n",
    "    print(\"----------------------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### variacaoCapacidadeVazaoTrecho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variacaoCapacidadeVazaoTrecho():\n",
    "    print(\"Working on variacaoCapacidadeVazaoTrecho\")\n",
    "\n",
    "    subtable = load(\"variacaoCapacidadeVazaoTrecho_variacoesCapacidadeVazaoTrecho.csv\").drop(\"variacoesCapacidadeVazaoTrechoId\", axis=1)\n",
    "    main = load(\"variacaoCapacidadeVazaoTrecho.csv\")\n",
    "    \n",
    "    print(\"Subtable length (rows): \" + str(len(subtable)))\n",
    "    print(\"Main table length (rows): \" + str(len(main)))\n",
    "    \n",
    "    final = pd.concat([subtable, main])\n",
    "    print(\"Merged table length (rows): \" + str(len(final)))\n",
    "\n",
    "    export(final, \"variacaoCapacidadeVazaoTrecho.csv\")\n",
    "    print('Modified \"variacaoCapacidadeVazaoTrecho.csv\".')\n",
    "\n",
    "    deleteFile(\"variacaoCapacidadeVazaoTrecho_variacoesCapacidadeVazaoTrecho.csv\")\n",
    "    print('Deleted \"variacaoCapacidadeVazaoTrecho_variacoesCapacidadeVazaoTrecho.csv\". Use \"variacaoCapacidadeVazaoTrecho.csv\" instead.')\n",
    "    print(\"----------------------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grandezaEnsaioMapaAnaliseAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grandezaEnsaioMapaAnaliseAPS():\n",
    "    print(\"Working on grandezaEnsaioMapaAnaliseAPS\")\n",
    "\n",
    "    subtable = load(\"mapaAnaliseAPS.csv\")\n",
    "    main = load(\"grandezaEnsaioMapaAnaliseAPS.csv\")\n",
    "    \n",
    "    subtable.rename(columns={\"id\": \"idMapaAnalise\"}, inplace=True)\n",
    "\n",
    "    main = main.merge(subtable, \"left\", \"idMapaAnalise\")\n",
    "\n",
    "    export(main, \"grandezaEnsaioMapaAnaliseAPS.csv\")\n",
    "    print('Modified \"grandezaEnsaioMapaAnaliseAPS.csv\".')\n",
    "\n",
    "    deleteFile(\"mapaAnaliseAPS.csv\")\n",
    "    print('Deleted \"mapaAnaliseAPS.csv\". Use \"grandezaEnsaioMapaAnaliseAPS.csv\" instead.')\n",
    "    print(\"----------------------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline de tratamento para arquivos específicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specificFilesPipeline():\n",
    "    idElo()\n",
    "    pesoMedioTransporteProduto()\n",
    "    regraBlendagemProduto()\n",
    "    siteProdutivoAPS()\n",
    "    submodalTransporte()\n",
    "    variacaoCapacidadeVazaoTrecho()\n",
    "    grandezaEnsaioMapaAnaliseAPS()\n",
    "\n",
    "specificFilesPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFiles = os.listdir(csvFilesPath)\n",
    "print('Final number of csv files in \"csvs\" directory: ' + str(len(csvFiles)))\n",
    "print(\"Informative tables: \" + str(len([f for f in csvFiles if f .endswith(\"APS.csv\")])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtro de colunas\n",
    "\n",
    "No processo de agregar subtabelas em suas respectivas tabelas principais, colunas com nomes idênticos receberam os sufixos \"_x\" e \"_y\" para serem diferenciadas. Isso ocorreu especificamente com *merges* realizados a partir das subtabelas prefixadas com *siteProdutivo*. Logo, essas colunas foram renomeadas e também foram excluídas as colunas de identificadores de índice em tabelas principais, pois já não são úteis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tryRemovingReferenceCol(fileName : str):\n",
    "    global alteredFiles\n",
    "    df = load(fileName)\n",
    "    \n",
    "    idCol = [c for c in df.columns if c.endswith(\"Id\")]\n",
    "    \n",
    "    if not len(idCol):\n",
    "        return\n",
    "    \n",
    "    df.drop(idCol[0], axis=1, inplace=True)\n",
    "    export(df, fileName)\n",
    "    print(\"Removed reference column from \" + fileName)\n",
    "    print(\"----------------------------------------------------------------------------------------------------------------------------\")\n",
    "    alteredFiles += 1\n",
    "\n",
    "\n",
    "def tryRenameXYCols(fileName : str):\n",
    "    global alteredFiles\n",
    "    df = load(fileName)\n",
    "\n",
    "    xyCols = [c for c in df.columns if c.endswith((\"_x\", \"_y\"))]\n",
    "\n",
    "    if not len(xyCols):\n",
    "        return\n",
    "    \n",
    "    for i in xyCols:\n",
    "        if i.endswith(\"_x\"):\n",
    "            df.rename(columns={i: i.removesuffix(\"_x\")}, inplace=True)\n",
    "        else:\n",
    "            df.rename(columns={i: \"site\" + i.removesuffix(\"_y\").capitalize()}, inplace=True)\n",
    "    \n",
    "    print(\"Renamed x/y columns from \" + fileName)\n",
    "    print(\"----------------------------------------------------------------------------------------------------------------------------\")\n",
    "    alteredFiles += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alteredFiles = 0\n",
    "\n",
    "for fileName in csvFiles:\n",
    "    tryRemovingReferenceCol(fileName)\n",
    "    tryRenameXYCols(fileName)\n",
    "\n",
    "print(\"Modified files: \" + str(alteredFiles))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
